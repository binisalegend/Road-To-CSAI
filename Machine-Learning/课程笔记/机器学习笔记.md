# 什么是机器学习
---
“Field of study that gives computers the ability to learn without being explictly programmed”  ---by Arthur Samuel

# 监督学习(Supervized Learning)
---

> [!important] 监督学习的重要特征
> 通过给出包含有 **“正确答案”** 的训练算法数据集让机器进行学习，最终实现让计算机无需接收“output label”，仅通过接收到的输入即可给出相应的预测输出

## 回归(Regression)
> [!TITLE] 回归
> 通过无数可能的数据中预测**一个**数据(predict numbers)

## 分类(Classification)
> [!TITLE] 分类
> 预测类别(predict categories)

# 无监督学习(Unsupervized Learning)
---
> [!IMPORTANT] 无监督学习的重要特征
> 数据集中仅包含输入标签$x$但不包含输出标签，算法需要在数据集中发现某种结构

## 聚类(Clustering)
> [!TITLE] 聚类
> 将一定量没有标签的数据自动分组到集群中

## 异常检测(Anomaly detection) 
> [!TITLE] 异常检测
> 检测异常数据

## 降维(Dimensionality reduction)
> [!TITLE] 降维
> 将大量数据集压缩为小数据集，并且尽可能地减小损失

# 线性回归模型
---
## 常用符号对照
| 符号(Notation) | 含义(Meanings) |
| ---- | ---- |
| $x$ | 输入变量("input" variable feature) |
| $y$ | 输出变量("output" or "target" variable) |
| $m$ | 训练集大小(num of training examples) |
| $(x, y)$ | 单个训练样例(single training example) |
| $(x^{(i)}, y^{(i)})$ | 第$i$个训练样例($i^{th}$ training example) |
| $\hat y$ | $y$的预测输出结果 |

## 回归方程(成本函数)拟合
> [!NOTE] 单变量线性回归模型(Univariate linear regression)
$$f_{w, b}(x) = wx+b$$

> [!IMPORTANT] 平方误差成本函数(Squares error cost function)
> $$J(w, b) = \frac{1}{2m}\sum\limits_{i=1}^{m}(\hat y^{(i)}-y^{i})^{2}$$
> 也可以写作
> $$J(w, b) = \frac{1}{2m}\sum\limits_{i=1}^{m}(f_{w,b}(x^{(i)})-y^{i})^{2}$$

# 批量梯度下降算法(Batch Gradiant descent algorithm)

> [!IMPORTANT] 梯度下降算法公式
> $$w = w - \alpha \frac{\partial}{\partial w}J(w, b)$$
> $$b = b - \alpha \frac{\partial}{\partial b}J(w, b)$$
> $\alpha$: 学习率(learning rate)，控制梯度下降的速率

- 为了同时更新$w,b$的值(Simultaneous update)，一定要同时计算出更新后的$w,b$的值后再进行更新，即在计算$b_{tmp}$时代入的$w$依然是**未更新的$w$** $$\begin{aligned}w_{tmp} = w - \alpha \frac{\partial}{\partial w}J(w, b)\\
b_{tmp} = b - \alpha \frac{\partial}{\partial b}J(w, b)\\
w = w_{tmp} \\
b = b_{tmp}\end{aligned}$$
> [!IMPORTANT] 同时，通过对平方误差成本函数进行求导，梯度下降算法公式将转化为：
> $$\begin{aligned} w = w - \alpha \frac{1}{m}\sum\limits_{i=0}^{m-1}(f_{w,b}(x^{(i)})-y^{(i)})x^{(i)} \\b = b - \alpha \frac{1}{m}\sum\limits_{i=0}^{m-1}(f_{w,b}(x^{(i)})-y^{(i)})\end{aligned}$$

- "batch": 在每次梯度下降更新过程中，都查看整个训练集的数据

# 多变量线性回归(Linear Regression with Multiple Variables)
---
> [!IMPORTANT] 多变量线性回归方程(Multiple linear regression)
> $$f_{\vec w,b}(\vec x)=\vec w \cdot \vec x+b=w_{1}x_{1}+w_{2}x_{2}+\dots+w_{n}x_{n}+b$$
> $$\vec w=[w_{1}~w_{2}\dots w_{n}]~~~\vec x=[x_{1}~x_{2}\dots x_{n}]$$

## 矢量化(Vectorization)
- 可以借助Python中的线性代数库`Numpy`来进行矩阵运算，如`w = np.array([1.0, 2.5, -3.3])`
> [!NOTE] 矢量化对比
> `Numpy`函数能够在计算机中使用并行硬件(parallel hardware)
>
> 矢量化：`f = np.dot(w, x) + b`
>
> 函数：`f = w[0] * x[0] + w[1] * x[1] + b`

## 特征缩放(Feature scaling)
> [!IMPORTANT] 基本思路
> 将所有特征的尺度都尽可能缩放到-1与1之间

> [!NOTE] 目的
> 确保特征都具有相近的尺度，帮助梯度下降算法更快收敛

1. 直接除以数据范围最大值，即$$x_{1,scaled} = \frac{x_{1}}{x_{rangeMAX}}$$
2. 均值归一化(Mean Normalization)
   先计算数据集上的平均值$\mu$，再求得$$x_{1,scaled}=\frac{x_{1}-\mu}{x_{MAX}-x_{MIN}}$$
3. Z均值归一化(Z-score Normalization)
   首先计算数据集的标准差$\sigma$(也是正态分布的标准差$\sigma$)，再求得$$x_{1,scaled}=\frac{x_{1}-\mu_{1}}{\sigma_{1}}$$

## 学习率的选择
### 查看梯度下降是否正确运行
1. 绘制学习曲线(Learning Curve)
   通过绘制$J(\vec w, b)$与迭代次数(iterations)的关系曲线，观测算法在何时趋于收敛，查看在梯度下降的每次迭代后$J$的变化情况，正确情况下每一次的$J$都会下降，如果在某一次迭代后$J$的值上升，可能是学习率$\alpha$选取过大
2. 采用自动收敛测试(automatic convergence test)
   令$\varepsilon=10^{-3}$，如果在一次迭代中$J(\vec w, b)$减少的值小于$\varepsilon$的值，则可以声明收敛

> [!NOTE] 学习率选取
> 尝试每一次的学习率比上一次的稍大三倍左右，找到合适的学习率
>
> $\alpha = 0.01,~0.03,~0.1,~0.3,~1,~3,~10$


## 特征工程(Feature engineering)与多项式回归(Polynomial Regression)
> [!info] 特征工程基本思路
> 通过对问题的知识或直觉来设计新的功能变量(features)，通常通过转化和结合数据的原始特征，使学习算法更容易做出准确的预测

![](Pasted%20image%2020240122175022.png)
- 如果采用多项式回归模型，在运行梯度下降算法前进行特征缩放十分有必要

## 正规方程(Normal Equation)
> [!TITLE] 原理
> 正规方程通过求解以下方程来寻找使得代价函数最小的参数
> $$\frac{\partial}{\partial \theta_{j}}J(\theta_{j})=0$$

假设我们的训练集特征矩阵为 $X$（包含了 ${{x}_{0}}=1$）并且我们的训练集结果为向量 $y$，则利用正规方程解出向量 $$\theta ={{\left( {X^T}X \right)}^{-1}}{X^{T}}y$$
> [!NOTE] 梯度下降与正规方程的比较:
> 
| 梯度下降             | 正规方程                                     |
| ---------------- | ---------------------------------------- |
| 需要选择学习率$\alpha$  | 不需要选择学习率                                      |
| 需要多次迭代           | 一次运算得出                                   |
| 当特征数量$n$大时也能较好适用 | 需要计算${{\left( {{X}^{T}}X \right)}^{-1}}$ 如果特征数量n较大则运算代价大，因为矩阵逆的计算时间复杂度为$O\left( {{n}^{3}} \right)$，通常来说当$n$小于10000 时还是可以接受的 |
| 适用于各种类型的模型       | 只适用于线性模型，不适合逻辑回归模型等其他模型                  |

- 总结就是说，当数据量较小时可以选用正规方程
- 正规方程的python实现如下：
  ~~~python
  import numpy as np
    
  def normalEqn(X, y):
    
	  theta = np.linalg.inv(X.T@X)@X.T@y #X.T@X等价于X.T.dot(X)
    
	  return theta
  ~~~

# 逻辑回归(Logistic Regression)
---
> [!warning] 
> 尽管称作“回归”，但是逻辑回归是用来进行分类任务的

- 只有两种类别的分类问题：二进制分类(Binary classification)，仅需分为`negative class`(false or 0)和`positive class`(true or 1)两种

## 逻辑函数(Sigmoid function)
> [!IMPORTANT] Sigmoid函数
> $$g(z) = \frac{1}{1+e^{-z}}$$

- Sigmoid函数位于0到1之间，当取0时与y轴相交与0.5 

> [!IMPORTANT] 将线性回归模型与Sigmoid函数相结合，得到的逻辑回归模型为：
> $$f_{\vec w,b}(\vec x) = g(\vec w \cdot\vec x+b)=\frac{1}{1+e^{-(\vec w\cdot\vec x+b)}}$$

- 对于这样的表述$$f_{\vec w,b}(\vec x)=P(y=1|\vec x;\vec w,b)$$表示在给定由$\vec w$和$b$作为参数决定的$\vec x$的前提下，$y=1$的概率

## 决策边界(Decision Boundary)
> [!summary] 定义
> 将令$z=\vec w\cdot\vec x+b=0$的回归曲线称为决策边界(Dicision boundary)

可以使用非常复杂的模型来适应复杂形状的判定边界：
$$\begin{aligned}g(z) = g(x_{1}+x_{2}-1) \\g(z) = g(x_{1}^{2}+x_{2}^{2}-1)\\ g(z) = g(w_{1}x_{1}+w_{2}x_{1}^{2}+w_{3}x_{1}x_{2}+w_{4}x_{2}^{3}) \end{aligned}$$

## 成本函数(Cost function)
> [!SUMMARY] 逻辑回归的代价函数
> $$Loss\Big(f_{\vec{w},b}\Big(\vec{x}^{(i)}\Big),y^{(i)}\Big)=\begin{cases}\quad-\log\Big(f_{\vec{w},b}\Big(\vec{x}^{(i)}\Big)\Big)&\text{if}~y^{(i)}=1\\-\log\Big(1-f_{\vec{w},b}\Big(\vec{x}^{(i)}\Big)\Big)&\text{if}~y^{(i)}=0\end{cases}$$
> $$Cost=J(\vec w, b)=\frac{1}{m}\sum\limits_{i=1}^{m}Loss\Big(f_{\vec{w},b}\Big(\vec{x}^{(i)}\Big),y^{(i)}\Big)$$
> $$J(\vec{\mathbf{w}},b)=-\frac{1}{m}\sum_{i=1}^{m}\left[y^{(i)}\mathrm{log}\left(f_{\vec{\mathbf{w}},b}(\vec{\mathbf{x}}^{(i)})\right)+(1-y^{(i)})\mathrm{log}\left(1-f_{\vec{\mathbf{w}},b}(\vec{\mathbf{x}}^{(i)})\right)\right]$$
> ![](ffa56adcc217800d71afdc3e0df88378.jpg)

> [!NOTE] 代价函数$Loss$可以简化统一表示为：
> $$L\left(f_{\vec{W},b}(\vec{x}^{(i)}),y^{(i)}\right)=-y^{(i)}\mathrm{log}\left(f_{\vec{W},b}(\vec{x}^{(i)})\right)-(1-y^{(i)})\mathrm{log}\left(1-f_{\vec{W},b}(\vec{x}^{(i)})\right)$$
> 代入$y^{(i)}$即可得到上述逻辑回归代价函数
>
> python代码表示为：
> ~~~Python
def cost(theta, X, y):
  theta = np.matrix(theta)
  X = np.matrix(X)
  y = np.matrix(y)
  first = np.multiply(-y, np.log(sigmoid(X * theta.T)))
  second = np.multiply((1 - y), np.log(1 - sigmoid(X * theta.T)))
  return np.sum(first - second) / (len(X))
> ~~~

- 另外，对于逻辑回归的梯度下降以及特征缩放等操作，在形式上与线性回归完全相同，也为$$\begin{aligned} w = w - \alpha \frac{1}{m}\sum\limits_{i=0}^{m-1}(f_{w,b}(x^{(i)})-y^{(i)})x^{(i)} \\b = b - \alpha \frac{1}{m}\sum\limits_{i=0}^{m-1}(f_{w,b}(x^{(i)})-y^{(i)})\end{aligned}$$但是由于$f_{\vec w,b}$变为了`sigmoid`函数，所以本质上梯度下降还是不同的

- 还有一些优化代价函数的更高级的算法，例如共轭梯度法(BFGS)、限制变尺度法(L-BFGS)等

## 过拟合(Overfitting)
- 拟合出的模型具有很高的方差(high bias)，即过度贴合了训练集，但是无法对测试集做出很好的预测

> [!NOTE] 解决过拟合问题的方法
> 1. 收集更多训练数据
> 2. 选择或减少一些训练特征(feature selection): 手动选取一些特征保留，或者使用一些模型选择算法(PCA等)
> 3. 正则化(Regularization): 收缩参数值，保留特征参数

## 正则化(Regularization)
> [!IMPORTANT] 正则代价函数
> $$J\left(\vec w,b\right)=\frac1{2m}[\sum_{i=1}^{m}\left(f_{\vec w, b}(\vec x^{(i)})-y^{(i)}\right)^{2}+\lambda\sum_{j=1}^{n}w_{j}^{2}]$$
> 其中$\lambda$为正则化参数

- 值得注意的是，一般我们不会对常数项参数$b$进行正则化

### 正则化线性回归
$$\begin{gathered}
\begin{aligned}&w_j=w_j-\alpha\left[\frac1m\sum_{i=1}^m\left[(f_{\overline{w},b}(\vec{x}^{(i)})-y^{(i)})x_j^{(i)}\right]+\frac\lambda mw_j\right]\end{aligned} \\
b=b-\alpha\frac{1}{m}\sum_{i=1}^{m}(f_{\vec{w},b}\big(\vec{x}^{(i)}\big)-y^{(i)}\big) \\ \end{gathered}$$

将$w_{j}$做变换，得到：$$w_{j}=w_{j}(1-\alpha\frac{\lambda}{m})-\alpha\frac{1}{m}\sum\limits_{i=1}^m(f_{\vec w,b}(\vec w^{(i)})-y^{(i)})x_{j}^{(i)}$$即在每次梯度下降过程中，略微减小$w_{j}$的值，以起到正则化效果
### 正则化逻辑回归
梯度下降形式上与线性回归相同，注意$f_{\vec w,b}$变为`sigmoid`即可

# 神经网络(Neural Networks)
> [!TIP] 整体结构
> `input layer` $\rightarrow$ `hidden layer` $\rightarrow$ `output layer`

> [!IMPORTANT] 神经网络层传递
> $$a_{j}^{[l]} = g(\vec w_{j}^{[l]}\cdot \vec a^{[l-1]} + b_{j}^{[l]})$$
> $\vec a^{[l-1]}$表示上一层的输出值
> 
> $\vec w_{j}^{[l]}, b_{j}^{[l]}$表示第$l$层中第$j$单元的参数
> 
> $a_{j}^{[l]}$表示第$l$层第$j$单元的激活值
> 
> $g$表示激活函数(activation function)，如`sigmoid`函数

## 前向传播(forward propagation)
> [!TIPS] tips
> 就是一种沿神经网络传递进行推理的方式，用于应用神经网络进行推理

## 神经网络的结构
- 创建一个隐藏层
  ```python
  x = np.array([[200.0, 17.0]])
  layer_1 = Dense(units=3, activation = 'sigmoid')
  a1 = layer_1(x)
  """
  >>> a1
  >>> tf.Tensor([[0.2 0.7 0.3]], shape=(1, 3), dtype=float32)
  """
  ```
  其中，`Dense`表示全连接致密层，`units`为该层中的单元数或输出维度，`activation`表示激活函数

## `Numpy`和`Tensorflow`中的数据类型
1. 矩阵表示(matrix)
   对于$\begin{bmatrix}0.1&0.2\\-3&-4\\-.5&-.6\\7&8\end{bmatrix}$，维数(`x.shape == (4, 2)`)，应用`Numpy`进行导入表示为：
   ```python
   x = np.array([[0.1, 0.2,],
			 [-3.0, -4.0,], 
			 [-0.5, -0.6,], 
			 [7.0, 8.0,]])
   ```

2. 向量表示(vector)
   `x = np.array([200, 17])`这种向量表示方式，其实也是`(1, 2)`维矩阵表示；但在`Tensorflow`中，我们更通常使用`x = np.array([[200, 17]])`这种矩阵方式来表示，以提高大规模运算的效率

3. 张量(tensor)表示
   使用`a1.numpy()`可以将张量变量转化为`Numpy`形式的向量

## 构建神经网络
1. 应用`Sequential`函数(顺序框架)
   `Sequential`函数可以将几层神经网络进行连接，使其直接构成一个神经网络而不用我们手动去传递层间激活数据，即
   ~~~python
   # 一种表示
   layer_1 = Dense(units=3, activation = 'sigmoid')
   layer_2 = Dense(units=1, activation = 'sigmoid')
   model = Sequential([layer_1, layer_2])
   # 更简洁的一种表示
   model = Sequential([
	   Dense(units=3, activation = 'sigmoid'), 
	   Dense(units=1, activation = 'sigmoid')])
   model.compile(...)
   model.fit(x, y)
   model.predict(x_test)
   ~~~

2. 数据正则化
   使用`norm_x = tf.keras.layers.Normalization(axis=)`可以对数据进行正则化处理，使数据平均值为0，标准差为1，具体操作如下：
   ~~~python
   norm_l = tf.keras.layers.Normalization(axis=-1)
   norm_l.adapt(X)  # learns mean, variance
   Xn = norm_l(X)
   ~~~

3. 获取和更新`layers`权重参数
   ~~~python
   w, b = model.get_layer("layer_1").get_weights()
   model.get_layer("layer_1").set_weights([w, b]) # w, b为ndarray类型参数矩阵
   ~~~

4. 通过训练后的神经网络进行预测
   ~~~python
   X_test = np.array([
	   [200,13.9],  # postive example
       [200,17]])   # negative example
   X_testn = norm_l(X_test)  # Normalization
   predictions = model.predict(X_testn)
   ~~~
   **注意预测时一定要按照训练时的方式进行正则化**

> [!TIPS] `np.dot()`与`np.matmul()`区别
> 首先结论是优先用`np.matmul()`
> 
> `matmul()`不支持标量运算，即运算双方如果不是同一数据类型会报错，而`dot()`会转换为统一数据类型进行运算
> 
> PS: 也可以用$@$代替矩阵点乘

5. 手写一个神经网络层
   ~~~python
   # 循环写法
   def dense(a_in, W, b, g):
	   units = W.shape[1]
	   a_out = np.zeros(units)
	   for i in range(units):
		   a_out[i] = g(np.dot(W[:, i], a_in) + b[i])  # W[:,j]: 取出第j列
	   return a_out

   # 向量写法
   def dense(a_in, W, b, g):
	   return g(np.matmul(a_in, W) + b)
   ~~~
   为了便于理解，其实$W$这一参数矩阵样式为$\begin{bmatrix}-1&-3&5\\2&4&6\end{bmatrix}$，每一列代表着一组(一个单元)的参数$w_{1}, w_{2}$，因此$W.shape = (2, 3)$，$units = W.shape[1] = 3$


## 训练神经网络
> [!IMPORTANT] 重点两步
> `model.compile(loss=BinaryCrossentropy)`: 定义损失函数
> 
> `model.fit(X, Y, epochs=100)`: 定义训练集和训练次数

1. `BinaryCrossentropy()`(二元交叉熵损失)：应用于二分分类问题(binary classification)的最常用损失函数，实际上就是逻辑回归中的损失函数：$$L(f(\vec x), y) = -ylog(f(\vec x)) - (1 - y)log(1 - f(\vec x))$$$y$是训练集标签(label)，$f(\vec x)$是神经网络输出
2. `MeanSquaredError()`(均值平方误差)：应用于回归问题，计算平方损失

$$J(W, B) = \frac{1}{m}\sum\limits_{i = 1}^{m}L(f(\vec x), y^{(i)})$$被称为**交叉熵损失函数(cross entropy loss function)**，使用的训练方法即为**反向传播算法(back propagation)**

## 激活函数
> [!TIPS] 激活函数的意义
> 如果不使用激活函数而仅使用线性回归，线性函数的线性函数所得仍是一个线性函数，相当于我们没有对训练集做多层神经网络处理，而只是选取了某个单一参数。因此，在神经网络的隐藏层中尽量不要使用`linear activations`线性函数

> [!NOTE] 激活函数的选取
> 输出层对激活函数的选取一般取决于$Y$标签(label)的特征，如二分类$y$只有0或1，故`sigmoid`比较合适，正负均有的回归则线性回归比较合适，而仅有非负数的回归可以考虑`ReLU`
>
> 通常情况下建议隐藏层使用`ReLU`

1. `Sigmoid`函数：$$g(z) = \frac{1}{1+e^{-z}}$$
2. `ReLU`函数：代表整流线性单位(Rectified Linear Unit)，相对`sigmoid`的优势点在于仅有一段梯度消失区域，能更快进行梯度下降$$g(z) = max(0, z)$$
3. `LeakyReLU`函数：相较于`ReLU`对负轴部分加入了微小梯度(pytorch中$\alpha$默认0.01)，解决神经元死亡问题$$g(z)=\begin{cases}\quad x,\quad&if\quad x\geq0\\\alpha\times x,\quad&\text{otherwise}\end{cases}$$
4. `Linear activation`函数：(其实就是啥也没用)：$$g(z) = z$$
5. `Tanh`函数：利用双曲正切对数据进行激活，将元素调整到`(-1, 1)`区间$$g(z) = \frac{e^x-e^{-x}}{e^x+e^{-x}}$$
6. `Swish`函数：导数恒大于0，防止慢速训练期间，梯度逐渐接近0并导致饱和；同时在优化泛化工作中，受益于其平滑度也能起到很好效果：$$g(z) = \frac{x}{1+e^{-z}}$$
7. `Softmax`函数：详见下一节多分类问题(Multiclass)：$$g(z)=\frac{e^{z}}{\sum\limits_{k=1}^{N}e^{z_{k}}}$$

## 多类分类问题(Multiclass Classification)
> [!SUMMARY] 定义
> 进行有限多类型的分类，即$Y$ label可以选取大于2个类别A

### Softmax回归算法

|  | Softmax回归 | 逻辑回归 |
| ---- | ---- | ---- |
| possibility | $a_{j}=\frac{e^{z_{j}}}{\sum_{k=1}^{N}e^{z_{k}}}=\mathrm{P(y=j\|\vec{x})}$ | $a_{1} = g(z) = \frac{1}{1+e^{-z}} = P(y=1\|\vec x)$<br>$a_{2} = 1 - a_{1} = P(y=0\|\vec x)$ |
| Loss function | $Loss = -log~a_{j},~~if~y = j$ | $Loss = -y~log~a_1-(1-y)log~a_2$ |
| Cost function | $Cost = J(\vec{w},b)=-\frac1m\left[\sum_{i=1}^m\sum_{j=1}^N1\left\{y^{(i)}==j\right\}\log\frac{e^{z_j^{(i)}}}{\sum_{k=1}^Ne^{z_k^{(i)}}}\right]$ | $Cost=J(\vec w, b)=\frac{1}{m}\sum\limits_{i=1}^{m}Loss\Big(f_{\vec{w},b}\Big(\vec{x}^{(i)}\Big),y^{(i)}\Big)$$ |

- 将`Softmax`激活函数应用于输出层以实现多分类任务，我们称神经网络有一个**软最大输出(Softmax output)**

- 在`tensorflow`中应用`Softmax`函数进行训练时，定义损失函数需要用到**稀疏范畴交叉熵函数(SparseCategoricalCrossentropy)**，`Categorical`表示进行多分类问题，`Sparse`则体现了每个类别仅能取分类中的一个类别label

> [!TIPS] 减少数字舍入误差(Numerical Roundoff Errors)
> 可以不显式计算中间量，直接将中间两结合到熵损失函数计算中
> 
> 如在逻辑回归中，可以考虑将输出层的激活函数设置为`linear`线性激活，然后在损失函数定义中添加参数`from_digits=True`
> 
> 注意：采用如上方式进行预测时，需要使用`predict_value = tf.nn.sigmoid(model(X))`这样的语法来进行预测

### 多标签分类问题(Multilabel Classification)
- 训练出一个神经网络具有多个输出，判断是否有多个分类标签存在


## 高级优化算法(Optimization)
---
> [!TIPS] 使用优化器的语法
> `model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), loss=...)`

- `Adam`算法(Adaptive Moment estimation)：
   1. 当检测到梯度下降沿同一个相似方向下降，学习率过小时自动增大学习率$\alpha$；
   2. 在检测到梯度下降产生振荡(oscillating)时减小学习率$\alpha$使得梯度正常下降；
   3. 不使用全局学习率，对于每一个参数都有一个$\alpha$

## 其他神经网络层类型(Layer Types)
---
1. `Dense layer(密集层)`：前面所学的全部神经网络层均为密集层(全连接层)，即将上一层收到的激活值全部应用于下一层中进行计算
2. `Convolutional layer(卷积层)`：每个单元不对全部输入做操作，只对部分操作进行识别操作；具有更快的速度，需要更少的训练数据，不易过拟合

# 神经网络的误差分析(Diagnostic)
---
## 模型性能的评估
> [!NOTE] 划分训练集和测试集(以线性逻辑回归为例，即使用平方误差计算的模型)
> 最小化Cost函数：$J(\vec{w},b)={min}_{\vec{w},b}\left[\frac{1}{2m_{train}}\sum_{i=1}^{m_{train}}(f_{\vec{w},b}(\vec{x}^{(i)})-y^{(i)})^{2}+\frac{\lambda}{2m_{train}}\sum_{j=1}^{n}w_{j}^{2}\right]$
> 
> 评估测试集误差：$J_{test}(\vec w, b) = \frac{1}{2m_{test}}\biggl[\sum_{i=1}^{m_{test}}\bigl(f_{\vec{\mathrm{w}},b}\bigl(\vec{\mathrm{x}}_{test}^{(i)}\bigr)-y_{test}^{(i)}\bigr)^{2}\biggr]$
>
> **注意：对于训练和测试集的误差评估不包含正则化**

## 模型选择
> [!IMPORTANT] 交叉训练集
> 将数据集划分为训练集(training)、交叉验证集/开发集(cross validation)、测试集(test)
> 
> 其中，交叉验证集的误差被称为验证错误(validation error)$$J_{c\nu}(\vec{w},b)=\frac{1}{2m_{c\nu}}\left[\sum_{i=1}^{m_{c\nu}}\left(f_{\vec{w},b}\left(\vec{x}_{c\nu}^{(i)}\right)-y_{c\nu}^{(i)}\right)^{2}\right]$$

**通过查看最低的交叉验证集误差来选择模型**，而模型的泛化拟合误差(Estimate generalization error)则用测试集误差$J_{test}(\vec w, b)$来表示

## 偏差和方差(biad & variance)
1. 多项式次数$d$对偏差和方差的影响![](Pasted%20image%2020240128122825.png)
- 多项式次数$d$过小$\rightarrow$欠拟合(underfit)$\rightarrow$偏差过大(high bias)$\rightarrow$ $J_{train}$和$J_{cv}$都比较大
- 多项式次数$d$过大$\rightarrow$过拟合(overfit)$\rightarrow$方差过大(high variance)$\rightarrow$ $J_{train}$特别小，但$J_{cv}$较大

2. 正则化参数$\lambda$对偏差和方差的影响
   ![](Pasted%20image%2020240128144309.png)
   - 正则化参数$\lambda$过大(相当于所有参数都尽可能小，$f_{\vec x,b}\approx b$)$\rightarrow$欠拟合(underfit)$\rightarrow$偏差过大(high bias)$\rightarrow$ $J_{train}$和$J_{cv}$都比较大
   - 正则化参数$\lambda$过小(相当于没有进行正则化)$\rightarrow$过拟合(overfit)$\rightarrow$方差过大(high variance)$\rightarrow$ $J_{train}$特别小，但$J_{cv}$较大

### 建立表现基准(baseline level of performance)
- 通过一定的比较判断期望的误差能够最小达到多少，比较基准误差和训练集、交叉验证集的差距，来确定发生了偏差或是方差问题

### 学习曲线(learning curves)
1. 如果学习算法偏差较大，获得更多的训练集很可能并不会减小误差，因为模型并没有发生太大改变，依然不适用于这些数据![](Pasted%20image%2020240128150805.png)
2. 如果学习算法方差较大，获得更多的训练数据可能确实会有所帮助，因为更多的数据更加严谨的限定了曲线形状，而本身的曲线次数已经足以拟合出细微形状![](Pasted%20image%2020240128151127.png)

> [!IMPORTANT] 修正`high bias`和`high variance`的方法总结
> 修正高偏差问题：获取更多特征，提高多项式拟合次数，减小正则化参数$\lambda$
> 
> 修正高方差问题：获取更多训练集，减小训练特征维度，增大正则化参数$\lambda$

- 进行合适正则化后的大型神经网络相较于较小的神经网络并不会更多的出现过拟合问题，同时还能很好的解决欠拟合问题，即算力足够前提下更大的神经网络几乎没坏处。
- 在`tensorflow`中进行正则化的语法是在建立layers时加入参数 `kernel_regularizer=L2(lambda_value)`。其中$L1$正则化指参数$w$中各个元素绝对值之和，即产生稀疏权值矩阵用于特征选择；而$L2$正则化则与逻辑回归的正则化相同(平方和求平方根)，用于防止过拟合

## 添加数据的方式
1. 数据增强(data augmentation)：通过对已有的训练集做一些处理来产生新的训练集，如OCR图像识别中进行对比度改变，旋转等图像扭曲工作等失真变换，产生具有相同label的训练集。如将图像置于网格中引入网格的随机翘曲(random warpings)，来创建一个更为丰富的训练实例库；或是对音频添加一些环境噪声或是失真(distortions)类型等
2. 数据合成(data synthesis)：使用人工创建的全新的训练集来添加训练实例，例如使用计算机不同字体截图作为新的训练实例来增强对OCR任务的识别，主要用于图像识别任务

- 现代机器学习工作可以分为算法专注(Conventional model-centric approach)和数据专注(Data-centric approach)两种，在算法工作逐渐成熟的今天，获取数据这一工作受到越来越多的关注

## 迁移学习(transfer learning)
> [!NOTE] 原理
> 借助完成其他任务的模型，选取输出层之外的参数，更改输出层单元为匹配新任务的数量，进行训练。
> 
> 即先在较大训练集上训练神经网络(supervised pretraining)，再在较小训练集上进行参数调优(fine tuning)
> 1. 可以只训练输出层参数，适用于训练集较小的情况
> 2. 可以训练所有层参数，但将输出层之外的参数初始化为迁移模型的保留参数

> [!SUMMARY] 迁移学习的步骤
> 1. 下载在较大数据集上训练的相同类型预训练神经网络的参数
> 2. 在自己的个性化数据集上进行训练和参数微调

## 机器学习的项目流程

**确定项目范围(Scope project) $\rightarrow$ 收集数据(Collect data) $\rightarrow$ 训练模型(train model) $\rightarrow$ 发布项目(Deploy in production)![](Pasted%20image%2020240128184826.png)
- `MLOps`(machine learning operations)：构建(build)，部署(deploy)和维护(maintain)机器学习系统

## 对倾斜数据集(skewed datasets)的处理
倾斜数据集就可以理解为二分类问题中出现两种情况的概率并不均等，例如诊断一位患者是否患有某种罕见病，可能本身$y=1$的概率就仅有1%，但是我们最终得到的寻俩模型可能具有0.5%的误差，这时候就需要我们对倾斜数据集进行处理

在处理倾斜数据集问题时，我们通常使用不同的误差度量，而不仅仅是分类误差(classification error)来判断模型的好坏。

特别的，一组常见的误差度量标准是**精确度(precision)** 和 **召回率(recall)** 
1. 精确度等于 正确预测为某种输出的验证数 除以 预测为某种输出的总验证数$$Precision = \frac{\text{True positives}}{\# p r e d i c t e d~p o s i t i v e}=\frac{\text{True positives}}{\text{True pos + False pos}}$$
2. 召回率等于 正确预测为某种输出的验证数 除以 实际上为某种情况的总数$$Recall = \frac{\text{True positives}}{\# actual~p o s i t i v e}=\frac{\text{True positives}}{\text{True pos + False neg}}$$

**混淆矩阵(confusion matrix)** 是一个$2\times2$的矩阵，其中横轴表示实际类(二分类问题中即为1或0)；纵轴表示预测类，即模型在给定的例子中预测了什么![](Pasted%20image%2020240128192547.png)
### 准确率与召回率之间的权衡
1. 对于一些小概率事件分类，即我们希望有极高概率才预测为1时，可以提高决策边界阈值。因此提高了预测率，降低了召回率。这样我们可以尽可能减少被误认为的概率
2. 当我们希望尽可能对不确定的事件都预测为1时，可以降低决策边界阈值。因此降低了预测率，提高了召回率

> [!NOTE] F1分(F1 score)
> 更强调两者之间相对较小的一个，因为当两者中有一个值特别小的时候可能模型就不是特别有用。事实上，F1分其实就是$P$和$R$的调和平均值(harmonic mean)
> 
> $$F1 = \frac{1}{\frac{1}{2}(\frac{1}{P}+\frac{1}{R})} = \frac{2PR}{P+R}$$
> 

## 关于模型选择的lab记录

1. 关于数据导入
   对一维的`numpy`数组可以使用`np.expand_dims()`函数将类似`[0, 1, 2]`转化为矩阵形式的`[[0], [1], [2]]`以供后续运算
2. 关于划分训练集，验证集和测试集：
   `Scikit-learn`中有函数`train_test_split()`，具体调用：`x_train, x_test, y_train ,y_test = train_test_split(x, y, test_size=0.4, random_state=1)`
3. 关于特征缩放和计算偏差和标准差：
   1. `Scikit-learn`中调用`StandardScaler`类进行正则化同时计算$z$分数，其中$z = \frac{x-\mu}{\sigma}$(感觉理解成正态归一也行)，`fit_transform()`对数据集进行计算；调用计算类的`mean_`和`scale_`方法可以导出数据集的均值和标准差
   2. 值得注意的是，在进行验证集验证工作时，一定要用训练集进行正则化的参数来进行正则化！因此可以直接用之前的`scaler_linear`来进行操作，并且由于之前进行了`fit`操作，可以直接使用`transform(x_cv)`来进行正则化和计算相关参数
   ~~~python
   # Initialize the class
   scaler_linear = StandardScaler()
   
   # Compute the mean and standard deviation of the training set then transform it
   X_train_scaled = scaler_linear.fit_transform(x_train)
   
   print(f"Computed mean of the training set: {scaler_linear.mean_.squeeze():.2f}")
   print(f"Computed standard deviation of the training set: {scaler_linear.scale_.squeeze():.2f}")
   ~~~
4. 关于模型评估
   1. 对于均值平方误差(MSE)可以直接使用`Scikit-learn`库中的函数：`J_train(w, b) = mean_squared_error(y_train, y_predict) / 2`
   2. 对于分类问题的误差，可以使用`np.mean(y_predict != y_actual)`函数来进行计算，相当于计算出错误预测数除以标签总数
5. 关于添加高阶多项式特征
   - 可以使用`PolynomialFeatures(degree=2, include_bias=False, interaction_only=False)`类似的语法，这样会添加一个新的关于$x^{2}$的特征
   - 也可以在一定范围内测试添加多项式的度数，保存下每个模型的`cv_mse`，应用`np.argmin()`函数来选取最优模型

# 决策树
---
> [!NOTE] 定义
> 其实现在还没咋看懂（）感觉就是二叉树最后叶节点是个判定那种

## 决策树学习
1. 选择在每个节点上使用什么特性进行拆分
   - 决策树选择特征的目的始终是为了最大限度**提高纯度(Maximize purity)**，即尽可能地让子集接近全部是某一类；
   - 个人理解上，感觉也是为了尽可能减少树的深度
2. 何时停止节点分裂
   1. 当一个节点中全部都是某一类(熵为0)
   2. 如果再次分裂就会超过树的最大深度
   3. 当纯度值的增大低于某个阈值(即纯度提升不够快或者是纯度下降)
   4. 节点上的示例数量小于某个阈值

## 测量纯度(熵entropy)
> [!IMPORTANT] 熵的公式定义: 是一种数据杂质含量的度量
> $$H(p_1)=-p_1 log_2(p_1)-(1-p_1)log_2(1-p_1)$$
> 同时可以通过加权平均数(权值为左右子树中示例数占总数的比例)对左右子树的熵值进行结合


- 相当于我们在选取拆分特征时，就是在选取使得熵下降最快的特征，在决策树中被称为**信息增益(information gain)**
  - 我们选取特征时应该选择相较于父节点熵值减小最多的特征作为拆分依据。因为熵值下降较小，说明我们只是不必要的增加了树的大小
- 最终，信息增益的表达式为$$IG(p_1) = max(H(p_1))=H(p_{1}^{root})-(w^{lchild}H(p_{1}^{lchild})+w^{rchild}H(p_{1}^{rchild}))$$


## 使用分类特征的一种单热度编码(one-hot encoding)
> [!IMPORTANT] 定义
> **尤其适用于处理多个离散特征**
> 
> 当一个分类特征具有$k$种可能的情况时，创建$k$个二进制特征来表示当前特征，称为`one-hot encoding`

## 处理连续有价值特征
选取每个示例中值计算阈值位于每处时的信息增益，选取最大的阈值作为拆分依据对连续值特征进行拆分![](Pasted%20image%2020240129183025.png)

## 回归树
- 决策树的推广，可以不仅应用于分类算法，可以应用为回归算法进行回归预测![](Pasted%20image%2020240129183501.png)
- 和决策树所相近的一个问题是，在节点上如何选择特征进行划分。在回归树问题上，我们试图减少**划分结果权重y的方差**，因此我们需要选择一个最大化减小方差的特征作为分裂依据，即：$$IG(p_1) = max(Var(p_1))=Var(p_{1}^{root})-(w^{lchild}Var(p_{1}^{lchild})+w^{rchild}Var(p_{1}^{rchild}))$$

## 构建多个决策树(tree ensemble)
- 受限于单个决策树对微小数据变化及其敏感，即有可能改变一个数据会导致整个树结构发生改变，因此构建一个决策树的集合使结构变得稳定是很有必要的
- 对于决策森林中的每一棵决策树可能都是一种合理的树结构，因此当我们进行预测时，需要将测试用例在全部树结构中进行测试，并对结果进行少数服从多数预测
- 决策森林的主要工作便是使整体算法对任何单个树所做的工作不是那么敏感
- 构建决策森林的步骤：(bagged dicision tree)
  1. 通过**放回抽样(Sampling with replacement)方法**构建一个新的与原数据集大小一致的数据集，在新的数据集上构建决策树
  2. 对于此时决策树的构建，我们采用**随机森林算法(random forest)**，即对于每一个我们要开始划分的节点，只能从$n$种特征中随机选择$k$个作为划分依据(数据量较大时通常选择$k=\sqrt n$)；即只能选择$k$个特征中信息增益最大的特征来划分
  3. 循环执行步骤1、2，假设构建了$B$棵决策树($B$的增大不会导致结果错误，可能会导致性能提升的不是特别明显)
  4. 在所有获得的决策树上进行预测并得出最终结果

## XGBoost(eXtreme Gradient Boosting)
- 相较于随机森林算法，`XGBoost`在构建每棵决策树时，不是以相同的概率进行放回抽样，而是更高概率的选择在之前训练树中出现错误的样例，这同样是一种**刻意练习**工作的展示
- 优势点：
  1. 强化树的一种开源形式
  2. 效率极高
  3. 有很好的进行特征划分和停止迭代特征的选择方式
  4. 内置了正则化方式来防止过拟合
  5. 为每一个训练样例都内置了不同的权重
- 最简单的调用方式
  ~~~python
  # Classification Question
  from xgboost import XGBClassfier
  model = XGBClassifier()
  
  # Regression Question
  from xgboost import XGBRegressor
  model = XGBRegressor()
  
  model.fit(X_train, y_train)
  y_pred = model.predict(X_test)
  ~~~

## 何时选用决策树

### 决策树和决策森林
---
1. 决策树和决策森林通常可以很好地处理表格(tabular)数据，也称为结构化(structured)数据；然而，对于一些非结构化数据(如图像，音频，文字等)，决策树结构可能就不是特别有效了，此时神经网络就能发挥作用
2. 决策树的一个很大的优点便是其建立和训练速度相较神经网络较快，可以使我们更快的完成机器学习循环并有效提高学习算法性能
3. 一些较小的决策树或森林是很容易被解释的，即可以通过决策树结构来解释为什么会做出某种预测
4. 通常使用决策森林或是`XGBoost`

### 神经网络
---
1. 神经网络几乎适用于所有数据，不管是表格化数据还是非结构化数据，甚至包括结构化和非结构化组件的混合数据
2. 相较于决策树来说训练相对较慢
3. **能够进行迁移学习**，对于少量数据集使用在大量数据集上进行训练的预训练模型，能够更好的获得优异的性能
4. 能够将多个神经网络同时运行进行工作，更好的构建机器学习系统。根本原因在于神经网络的输出$y$或者$f(x)$是连续函数，他们本身就是可微的；因此即使将很多的模型串在一起，也可以在训练模型的同时进行梯度下降
5. 当构建一个多机器学习方法的机器学习系统时，应用多神经网络一起训练要比多决策树更容易

## 关于决策树的lab记录
1. 关于 `one-hot encoding`：Pandas中内置了`pd.get_dummies()`函数，能够自动对选中的变量进行单热度二进制操作![](Pasted%20image%2020240129231402.png)其中重点参数如下：
   1. `data=`：使用的数据矩阵
   2. `prefix=`：一个带有前缀的列表，这样你就知道你要处理的是哪个值
   3. 将进行热编码的列的列表，`prefix`和`columns`必须具有相同的长度
2. 使用`Scikit-learn`库中自带的 `DecisionTreeClassifier` 函数可以方便的构建决策树，语法如下：
   ~~~python
   model = DecisionTreeClassifier(min_samples_split=..., max_depth=..., random_state=...).fit(X, Y)  # 参数含义详见前面的note
   ~~~
   还可以用 `accuracy_score` 来计算决策判断的准确度
3. 对于随机森林的构建，可以调用 `RandomForestClassifier` 函数，相较于决策树函数多了一个参数 `n_estimators=100` ，即拟合多少棵决策树
4. 除了控制变量寻找参数以外，我们还可以调用 `GridSearchCV` 函数直接寻找最佳的参数组合，语法如下：
   ~~~python
   # use GridSearchCV to find the best parameters
   from sklearn.model_selection import GridSearchCV
   
   param_grid = {
       'n_estimators': [10, 50, 100, 500],
       'max_depth': [2, 4, 8, 16, 32, 64, None],
       'min_samples_split': [2, 10, 30, 50, 100, 200, 300, 700]
   }
   
   grid_search = GridSearchCV(estimator = RandomForestClassifier(random_state = RANDOM_STATE),
                            param_grid = param_grid,
                            cv = 3,
                            n_jobs = -1,
                            verbose = 2).fit(X_train, y_train)
   ~~~
5. 关于`XGBoost`的应用：
   1. 参数基本与随机森林相同，但是并不需要手动调参，同时要加入学习率`learning_rate`作为梯度下降参数
   2. 需要注意的另一个点是，在拟合`fit()`过程中，需要加入验证集参数`eval_set=[(X_eval, Y_eval)]`和迭代截至阈值`early_stopping_rounds=`
   3. XGBoost最大的优势就是在于操作极为简便，在某种程度上代码只有两行：
      ~~~python
      xgb_model = XGBClassifier(n_estimators = 500, learning_rate = 0.1, verbosity = 1, random_state = RANDOM_STATE)
      xgb_model.fit(X_train_fit, y_train_fit, eval_set = [(X_train_eval, y_train_eval)], early_stopping_rounds = 50)
      ~~~

# 无监督学习
---
## 聚类(Clustering)
> [!NOTE] 定义
> 通过观察一系列的数据点，自动寻找具有相似特征或关联的数据点

可以用于信息分类，星系划分，DNA检验等多个领域

## K-means聚类

### 定义和基本实现原理
> [!TITLE] K-means聚类
> 目标：将$N$个观测值划分到$K$个集合中
> 
> 步骤：
> 1. 随机选择$K$个位置$\mu_{1},\mu_{2},\cdots, \mu_{K}$作为初始的聚类中心。注意$\mu_{k}$都是向量，与训练样例具有相同的维度
> 2. 对于$m$个观测值，计算每一个观测值到$K$个聚类中心的距离，即$dis(x^{(i)}, \mu_{k})$，通常写作$min_{k}||x^{(i)}-\mu_{k}||^{2}$，也被称为**L2范数**。并将其划分到距离最近的聚类中心所在的集合，即令$c^{(i)}=\mu_{k}$
>    ~~~python
>    for i in range(m):
> 	   c_i = index(from 1 to K) of cluster centroid closest to x_i
>    ~~~
> 3. 对于每个聚类中心$k$的集合，计算集合中所有观测值的位置均值，更新聚类中心$\mu_{k}$
>    ~~~python
>    for i in range(K):
> 	   mu_k = mean of points assigned to cluster k
>    ~~~
> 4. 重复步骤2、3，直到每个观测点的分类不再变化，或聚类中心几乎不再变化，或达到预定迭代次数

### 优化目标

| 符号 | 表示含义 |
| ---- | ---- |
| $c^{(i)}$ | 训练样例$x_{i}$被划分到的聚类索引 |
| $\mu_{k}$ | 聚类中心$k$的位置坐标 |
| $\mu_{c}(i)$ | 训练样例$x_{i}$被划分到的聚类的聚类中心位置坐标 |

- K-means的成本函数为(也被称作失真函数Distortion function)$$J(c^{(1)},\ldots,c^{(m)},\mu_{1},\ldots,\mu_{K})=\frac{1}{m}\sum_{i=1}^{m}\lVert x^{(i)}-\mu_{c^{(i)}}\rVert^{2}$$![](Pasted%20image%2020240130152714.png)

### 初始化K-means(随机选择初始化聚类中心)
- 最普通的一种方式是直接随机选取$K$个训练样例$x_{i}$作为初始化聚类中心$\mu_{1},\mu_{2},\cdots,\mu_{K}$
- 另一种更加准确的方式是随机选取多种聚类中心并执行K-means算法，计算每种方式的$J$成本函数并选取失真函数最小的那种聚类方式

### 选择聚类簇数
1. Elbow method：感觉很玄学，就是根据聚类个数绘出$J$损失函数曲线，选择类似于“肘部”的聚类簇数![](Pasted%20image%2020240130154138.png)
2. 好吧这种更玄学，就是根据划分并完成K-means算法所要实现的下游任务的执行效果，来判断簇数$K$的选取是否合理

## 异常检测(Anomaly detection)
> [!TITLE] 定义
> 异常检测就是系统在接收一定的训练数据以后，能够通过判断一个新的测试实例是否与之前的训练样例相近，来进行异常检测

- 应用高斯分布(其实就是正态分布Normal distribution)，其概率密度函数如下：$$p(x)=\frac{1}{\sqrt{2\pi}\sigma}e^{\frac{-(x-\mu)^2}{2\sigma^2}}$$通过测试样例的正态概率来判断数据是否正常

### 构建异常检测系统
1. 选取$n$个可能出现异常情况的特征$x_{i}$
2. 计算参数$\mu_{1},\ldots,\mu_{n},\sigma_{1}^{2},\ldots,\sigma_{n}^{2}$，其中$\mu_{j} = \frac{1}{m}\sum\limits_{i=1}^{m}x_{j}^{(i)}$，$\sigma_{j}^{2} = \frac{1}{m}\sum\limits_{i=1}^{m}(x_{j}^{(i)}-\mu_{j})^{2}$
3. 建立密度估计模型，给定一个新的测试样例$x$，计算测试样例的概率密度函数$P(x)$，表示为所有特征概率的乘积：$$\begin{aligned} P(x) = p(x_{1};\mu_1,\sigma_1^2)*p(x_{2};\mu_2,\sigma_2^2)*\cdots*p(x_{n};\mu_n,\sigma_n^2)=\prod_{j=1}^{n}p(x_{j};\mu_{j},\sigma_{j}^{2})\\P(x) = \prod_{j=1}^{n}\frac{1}{\sqrt{2\pi}\sigma_{j}}\exp[-\frac{(x_{j}-\mu_{j})^{2}}{2\sigma_{j}^{2}}]~~~~~~~~~~~~~~~~~~~~~~~~~~~\end{aligned}$$其中每一项$x_{1},\mu_{1},\sigma_{1}^2$都表示某个特征发生的概率、均值和方差
4. 判定$P(x)\leq \varepsilon$，如果小于就判断为异常

### 开发和评估异常检测系统
- 实数分析(real-number evaluation)：在改变某个算法参数时，能够提供一个体现算法效果优劣的数值用于评估
  1. 我们可以通过在无监督训练集中的极少量已知标签样例，来划分训练集、交叉验证集和测试集，训练集都假定为普遍性实例，在交叉验证集和测试集中添加一致的异常实例用来调整$\varepsilon$参数；或者只划分一个交叉验证集包含全部的已知异常示例用于调整参数