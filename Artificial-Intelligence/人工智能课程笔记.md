# 机器学习(Machine Learning)
---
> Improve on *T*ask with respect to *P*erformance metric based on *E*xperience

- 主要从效果(Effectiveness)和效率(efficiency of the computation)两方面衡量

机器学习的必要性：未知环境和复杂系统，大规模数据挖掘，促进人类智能

**Objectiveness**和**Optimization**

## 监督学习
> [!SUMMARY] 基本思想
> 给定$x$和$f(x)$，试图求解出一个假设的(*hypothesis*)映射函数$x$逼近$f$，其主要任务如下：
> 1. 如何定义函数形式
> 2. 如何优化函数参数和函数结构

- Mean Square Error(MSE)：均值平方根误差

Ockham's Razor(奥卡姆剃刀原理)：在逼近数据的前提下令函数尽可能简单，使函数具有普适性

### 决策树(Decision Tree)
选择作为根节点的特征：以某个特征能将子节点分成几个独立性更强的部分

- Entropy(熵)：从函数**结果**进行计算$$I(\frac p{p+n},\frac n{p+n})=-\frac p{p+n}\log_2\frac p{p+n}-\frac n{p+n}\log_2\frac n{p+n}$$熵越大表示区分数据越混乱，越小表示越独立
- Remainder Entropy(剩余熵)：$$R(A) = \sum_{i=1}^v\frac{p_i+n_i}{p+n}I(\frac{p_i}{p_i+n_i},\frac{n_i}{p_i+n_i})$$
- 信息增益(Information Gain)：选择`IG`最大的特征作为根节点特征 $$IG(A) = I\left(\frac p{p+n},\frac n{p+n}\right)- R(A)$$

#### 预防过拟合(Overfitting)
1. 扩大数据集
2. 提前停止拟合
3. 允许在数据集上过拟合，但随后对模型做剪枝
   - 通过做DL(Description Length)分析，选取Code Length更低的决策树

### 贝叶斯推论
> [!NOTE] 贝叶斯定理
> $$P\left(h|D\right)=\frac{P\left(D,h\right)}{P\left(D\right)}=\frac{P\left(D|h\right)P\left(h\right)}{P\left(D\right)}$$其中$D$表示数据，$h$表示假设；$P(h|D)$表示后验概率(Posterior Probability)，$P(h)$表示先验概率(Prior Probability)，$P(D|h)$表示类条件概率(Class-conditional Probability)

- MAP(Maximum A Posterior)：最大后验估计，通过计算每个候选假设的后验概率找到最大项

- 简化类条件概率$P(D|h)$的形式方法：
  1. 朴素贝叶斯分类器(Naive Bayesian Classifiers, NBC)：假设各分量间没有关系，无需考虑协方差，每个分量都只有均值和方差需要考虑
  2. 贝叶斯信念网络(Bayesian Belief Classification, BBC)：将有关系的分量建立图模型联系
  3. 高斯混合模型(Gaussian Miature Model, GMM)：用简单的函数叠加形成复杂函数

#### 朴素贝叶斯分类器(NBC)
$$P\Big(D\Big|h\Big)=P\Big(d_1,\cdots,d_n\Big|h\Big)=\prod_iP\Big(d_i\Big|h\Big)$$即可以只看做各个特征概率之间的连乘

#### 贝叶斯信念网络(BBN)
在给定条件$Z$的时候假设特征$X$与$Y$相互独立，即$$P\Big(x_1,\cdots,x_l\Big|y_1,\cdots,y_m,z_1,\cdots,z_n\Big)=P\Big(x_1,\cdots,x_l\Big|z_1,\cdots,z_n\Big)$$

集合概率本质上是一个概率分布的表达形式，可以表示为$$P\left(x_1,\cdots,x_n\right)=\prod_{i=1}^nP\left(x_i\right|Parents\left(x_i\right)$$可以用有向图或条件概率表(Conditional Probability Table, CPT)表示![](Artificial-Intelligence/Pasted%20image%2020240602012513.png)
- 既能对概率分布做有效表达，又能限制其复杂性，使规模增长性由指数变为线性增长

- 编辑概率公式：$$P(x|y)=\alpha P(x,y) = \alpha\sum\limits_zP(x,y,z)$$其中$\alpha=P(y)^{-1}$，简单理解就是把$z$变量的所有取值都考虑一遍，这样相当于特征$z$不会影响到原有的情况。例如可以有$$\begin{align} P(B|j,m)&=\frac{P(B,j,m)}{P(j,m)}\\&=\alpha P(B,j,m)\\&=\alpha\sum\limits_{a}\sum\limits_{e}P(B,e,a,j,m) \end{align}$$

- 优化目标：极大似然估计(Maximum Likelihood Estimation, MLE)
- 优化方法：梯度上升$$\frac{\partial\ln P_w(D)}{\partial w_{ijk}}=\sum_{d\in D}\frac{P_w\left(x_{ij},u_{ik}|d\right)}{w_{ijk}}$$

## 无监督学习（聚类）
1. 计算度量簇(cluster)和数据之间的相似性：欧氏距离(Euclidean)，余弦夹角，切比雪夫(Chebyishev，多维中每一维中最大的距离)，闵可夫斯基距离(Minkowski)
2. 划分数据集
3. 确保聚簇算法具有可伸缩性

### 划分聚类
#### K-means聚类
可以直接看[K-means(K均值)算法](Classification-Algorithm/分类算法学习.md#K-means(K均值)算法)
1. 随机选取$k$个数据作为初始聚簇中心
2. 把其他数据划分到距离最近的聚簇中
3. 对新的聚簇重新计算均值聚簇中心
4. 重复Step2和3

- 优化方程：$$J\Big(X,\nu\Big) = \sum_{i=1}^{n}\sum_{i=1}^{k}\Big(u_{ij}\Big)^{m} {\rho\Big(d\Big(x_{i},\nu_{j}\Big)\Big)}$$其中$v_{j}$表示聚簇中心，$\rho(d(x_{i}, v_{j})) = ||x_{i}-v_{j}||^{2}$，$u_{ij} \in \{0,1\}$
- 当将优化方程中的$m=1,2,3\cdots$，$u_{ij}\in[0,1]$，即设$u_{ij}$为数据点$x_{i}$数据聚簇中心$v_{j}$的模糊度，此时方法称为模糊k均值(Fuzzy k-means, FCM)

- k-means算法的特征
  1. 线性算法复杂度：$O(tkn)$
  2. 局部最优
  3. 需要指定聚类的个数
  4. 对噪声和初始聚类中心的确定比较敏感

#### K-medoids聚类
K-中心点聚类，也叫做PAM(Partitoning Around Medoids)

方法上寻找每个聚簇的代表性数据，特点上能够很好的**减少噪声对聚类划分的影响**，是在确定中心点和计算聚类中心之间的迭代

1. 随机选取$k$个中心点
2. 计算每组中心点和其他数据的替代成本设为$TC_{ih}$
3. 如果最小的$TC_{ih}<0$，就用$h$替换中心点$i$
4. 重复Step2和3，直到$TC_{ih}\geq 0$

### 层次聚类
1. 自下而上的凝聚聚类(Bottom-Up Agglomerative Nesting)：滚雪球式，首先视每条数据都是一个聚簇，不断结合
2. 自上而下的分裂聚类(Top-Down Divisive Analysis)：细胞分裂式，首先视所有数据都是一个聚簇，按照彼此之间差异不断拆分

- 问题：计算效率偏低
  1. BIRCH：提出clusting feature(CF)，通过计算聚簇中节点个数、聚簇中所有节点线性距离之和以及**平方和**，只需要把所有数据扫描**一遍**![](Artificial-Intelligence/Pasted%20image%2020240603201853.png)
  2. CURE：用多个点数据代表一个聚簇的特征，令聚簇中数据不断向均值点收缩
  3. CHAMELEON：用图模型做聚类，边代表两节点之间的关联，通过切断相关性较差（距离较远）的边来实现图分割聚类![](Artificial-Intelligence/Pasted%20image%2020240603231440.png)

### 基于密度的聚类(Density-Based)
#### DBSCAN
1. Core：稠密区域的中心点
2. Border：在某稠密区域的边缘，但以其为中心无法构成稠密区域
3. Outlier：噪声数据

- DBSCAN 在每个数据点周围创建一个 epsilon 半径的圆，并将它们分类为核心点、边界点和噪声
  1. 如果数据点周围的圆至少包含“minPoints”个点，则该数据点是核心点Core
  2. 如果点数小于minPoints，那么它被归类为Border
  3. 如果epsilon半径内任何数据点周围没有其他数据点，那么它被视为Outlier

- 定义数据密度：
  1. Epsilon，Eps：邻域最大半径
  2. MinPoints，MinPts：最大半径区域内数据最小个数
  3. Neighbor：$N_{Eps}(p)=\{q\in D\mid dist(p,q)\leq Eps\}$
 
1. 密度直接可达(Directly Density-reachable)：$p$在$q$为中心的区域内，$q$是一个稠密区域中心点，即$$p\in N_{Eps}(q),~|N_{Eps}(q)|\geq MinPts$$如图中p是q的直接密度可达，但q不是p的直接密度可达(p不是中心点)![](Artificial-Intelligence/Pasted%20image%2020240603232733.png)
2. 密度可达(Density-reachable)：个人理解是$p$属于一个聚簇，$q$属于一个聚簇，这俩聚簇有交集的数据，并且有一个直接密度可达（？![](Artificial-Intelligence/Pasted%20image%2020240603234440.png)
3. 密度相连(Density-connected)：存在一个点$O$使$q$和$p$都密度可达![](Artificial-Intelligence/Pasted%20image%2020240603234543.png)

只需要对所有点扫描一遍，算法复杂度$O(N^{2})$

#### DENCLUE
1. 影响函数(Influence Function)：表示每个数据在其邻域的影响程度（用距离远近体现）
2. 密度函数(Density Function)：每个点的影响函数之和
3. 密度函数的最大值(Density Attractor)：密度极大值点，密度函数局部最大值

- 以中心定义的聚类(Center-Defined Clusters)：所有超过阈值的最大值都被视作聚类中心![](Artificial-Intelligence/Pasted%20image%2020240603235733.png)
- 任意形状的聚类(Arbitray-Defined Clusters)：如果存在密度函数连续超过阈值的路径，则合并聚类中心![](Artificial-Intelligence/Pasted%20image%2020240603235745.png)

### 网格聚类(Grid-based Clustering)
通过网格结构将数据划分为多个小区域来减少计算量，适用于大规模数据；但划分不精确

具体可以看一下这个帖子[基于方格的聚类方法](https://blog.csdn.net/shulianghan/article/details/105969685)

- Sting(Statistical information grid approach)：划分方格，构成不同层次结构的网格分辨率不同，分别对每个数据单元进行聚类
- Clique(Clusting in Quest)：引入 `subspace` 子空间概念，融合基于密度和网格的聚类方法，用空间划分表达聚类结果，不受数据访问顺序的影响

## 关联规则挖掘(Assosiation Rule Mining)
- 关联规则(Assosiation Rule)：使用机器学习方法探索在大量数据集中的变量间关系

### 支持可信框架(Support-Confidence Framework)


# 人工神经网络(Artificial Neural Network)
---



# 搜索与问题求解(Search and Problem Solving)
---




# 知识与推理(Knowledge and Reasoning)
---



# 进化计算(Evolutionary Computation)
---



# 群体智能(Swarm Intelligence)
---




# 新型人工智能(Nouvelle AI)
---
Agent定义：感知周围环境并对其作出反应

- Situatedness：存在于真实环境中
- Autonomous：自动化能实际操作的
- Proactive：具有一定的直接目标
- Reactive：对环境变化具有一定的反应能力
- Social Ability：同其他人、物具有一定的交互能力
- BDI(Belief, Desires, Intentions)

## 强化学习(Reinforcement Learning)
某一步的结果并不可知，具有一定的时间延后性，通过经验和不断试错来学习
	
- 状态函数(State Value Function)：$V^{\pi}(s)$
- 状态动作奖励函数(State-Action Value Function)：$Q^{\pi}(s,a)$
- Bellman Equation：$$V^{*}(s)=\operatorname*{max}_{a}\left(R(s,a)+\gamma\sum_{s^{\prime}\in\mathcal{S}}T(s,a,s^{\prime})V^{*}(s^{\prime})\right),\forall s\in\mathcal{S}$$

## Q-Learning
$$\pi^*\left(s_t\right)=\arg\max_a\left\lfloor f_R\left(s_t,a\right)+\gamma V^*\left(f_S\left(s_t,a\right)\right)\right\rfloor $$
$$Q\Big(s_t,a\Big)=f_R\Big(s_t,a\Big)+\gamma V^*\Big(f_S\Big(s_t,a\Big)\Big)$$
$$\hat{Q}(s,a)\leftarrow r(s,a)+\gamma\max_{a^{\prime}}\hat{Q}(s^{\prime},a^{\prime})$$

![](Artificial-Intelligence/Pasted%20image%2020240611102443.png)
## TD(Lambda) Learning
