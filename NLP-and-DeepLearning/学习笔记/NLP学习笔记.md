# Lecture 1
- 在传统的NLP中，将每一个单词作为一个单独的元素进行储存，而在深度学习中则会将每个单词以向量形式进行储存
- 在现在的深度学习方法中，我们采用分布式语义来寻找一个单词的相近含义的词汇，具体的方式则是通过寻找在相同语境下经常出现的词汇，例如我们可以在很多文本中寻找到 `banking` 这个单词，而在它所处环境附近的语句就在某种含义上体现了这个单词的含义；将上下文中出现的词汇视为向量，这些向量可以用于构建其他单词的语义，而每一个单词的语义由则由周围数以千计维度的向量所决定供机器来理解某个具体单词的词义，这被称为 `word embeddings`（词嵌入）
## Word2vec
- 基本原理是，我们可以选择一个语料库，为其中的每一个单词都创建向量 ；然后，我们可以通过一些列文本资料来训练这个模型，让它可以记录词汇间的相似度和出现的频率，根据中心词所在的向量周围的向量调整周围词汇在中心词周围出现的频率，以计算机的方式理解每个词汇的含义
