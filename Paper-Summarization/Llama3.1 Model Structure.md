# Summary
1. **预训练阶段**：大规模多语种语料库拆分为离散Tokens进行预训练，对于405B预训练数据集扩大至15.6T，标准预训练展开8K tokens的上下文窗口，随后进行持续的预训练，将上下文窗口扩展到128K Tokens
2. **后处理阶段**：整体对齐方法为多轮监督指令微调（SFT）+直接偏好优化（DPO）；最后添加了工具调用、提升编码问答等能力
3. **多模态编码器**：视觉模态编码器感觉就是text2img对训练；语音模态用了自监督方法，通过对输入语音进行部分掩码，通过离散token进行掩码重建
4. **视觉适配器**：将encoder集成到LLM里，由一系列交叉注意力层构成，将encoder数据形式馈送到LLM中；在训练adapter过程中会不断更新image encoder的参数，但不会更新LLM的参数；也在视频文本对上进行训练，使模型能够跨帧聚合信息
5. **语音适配器**：跟上面的差不多，适配器和编码器在监督微调过程中共同更新参数，但是LLM不会改变，添加了文本转语音系统

# Pre-Training
